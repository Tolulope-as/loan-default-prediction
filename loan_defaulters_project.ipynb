{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82823653-b571-45f0-b5cf-7855c5e632b6",
   "metadata": {},
   "source": [
    "## Predicting Loan Default Risk\n",
    "### Problem Statement:\n",
    "Develop a robust machine learning pipeline to predict loan default risk, enabling better credit decisions and minimizing financial losses.\n",
    "#### Target:good_bad_flag\n",
    "- good - will pay back\n",
    "- bad - will not payback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb878b97-db1f-413d-9400-a6ac9a1c8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532d983-3636-4d56-8d0f-7e65c49d2090",
   "metadata": {},
   "source": [
    "Our data comprises of Demographics, Financial and Previousrecords data each stored seperately in 3 different files , this are the link to those files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d51d40-bbae-4a8f-a4d8-d22c4657472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = 'https://raw.githubusercontent.com/Oyeniran20/axia_cohort_8/refs/heads/main/traindemographics.csv'\n",
    "data2 = 'https://raw.githubusercontent.com/Oyeniran20/axia_cohort_8/refs/heads/main/trainperf.csv'\n",
    "data3 = 'https://raw.githubusercontent.com/Oyeniran20/axia_cohort_8/refs/heads/main/trainprevloans.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625f5a2-6aea-4d3f-9b92-336a573e6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfddeb72-76f4-469a-a2ca-920013edece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71de5bf-e380-4683-947c-c9ed3fc313c4",
   "metadata": {},
   "source": [
    "### Data understanding of first dataset(Demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97cd14-ec16-4731-a58e-fdf5c0e5d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531e56c-57dd-41ce-a1de-76bc84873826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657b18f-2944-4f47-a224-6674867f2c30",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- The dataset contains 9 colums and 4346 rows\n",
    "- There are 2 numerical columns and 7 categorical columns\n",
    "- The features bank_branch_clients,  employment_status_clients and  level_of_education_clients all contain missing values\n",
    "- The following columns will be dropped due to their irrelevance - bank_branch_clients,longitude_gps,latitude_gps\n",
    "- Birthdate column needs transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8b461-edd0-47e7-b317-fdaf3924f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping irrelevant columns\n",
    "\n",
    "df1 = df1.drop(columns=['longitude_gps','latitude_gps'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b003f-84e2-467d-9acf-76e0bc39c561",
   "metadata": {},
   "source": [
    "#### Checking and dealing with Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532ac40-8cde-4769-b435-4fd8653e4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicate values\n",
    "\n",
    "df1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c3f9a-d17f-456e-9a3f-323602e786bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicates\n",
    "df1 = df1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642036f-ac28-4abe-93a2-06558569aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70272bbd-398f-4d42-abfd-2d27514ad80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce10880-5716-4bfb-90fa-cd80d4509457",
   "metadata": {},
   "source": [
    "#### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff353d1b-ed56-41ab-81cf-4d3954acf769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking total of null values\n",
    "\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ea595-bf76-4168-87a9-c1d879600a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of missing value in bank_branch\n",
    "4283/4346 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934b93f-80de-494e-bfe3-5b3833ba5288",
   "metadata": {},
   "source": [
    "This column will be dropped due to high % of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762036fa-5578-4e8f-ade4-47f62d6f39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of missing values in employment_status_clients\n",
    "\n",
    "648/4346 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701c884-58b9-4bf0-b5a6-b46898e57d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['employment_status_clients'] = df1['employment_status_clients'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab1f5a5-e45b-432f-bc5a-85d607abfff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of missing values in level_of_education_clients\n",
    "\n",
    "3748/4346 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c8529e-ff4c-459e-90e4-7ef67baf318d",
   "metadata": {},
   "source": [
    "The level_of_education_clients column is going to be dropped due to the high percentage of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67076b7d-fd6c-4020-bc85-d60605cf183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns=['level_of_education_clients','bank_branch_clients'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f09462-3604-42c8-a71e-5fb849f1b70f",
   "metadata": {},
   "source": [
    "#### Feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020c5a4-a5c9-4643-9e9b-435ca1de78f1",
   "metadata": {},
   "source": [
    "#### Creating new feature age from birthdate\n",
    "\n",
    "The birthdate feature has relevant information but in it's current form its not useful so we will transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbceb9c6-b60f-4c4e-bb04-7d800bf610fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['birthdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ecf39-7c6c-4ae6-bf3f-c70efae4af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of the zeros\n",
    "\n",
    "df1['birthdate'] = df1['birthdate'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4134ce-6e74-464f-a2d1-88b944433384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting only the year value \n",
    "\n",
    "df1['birthdate'] = df1['birthdate'].str.split('-').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ff728-8206-40a5-8fc6-74684b824a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting it from object to integer\n",
    "\n",
    "df1['birthdate'] = df1['birthdate'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00297477-b11c-4373-96f6-f0a1a8157f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['birthdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03136f-c5e8-448a-8b5a-4680d88e5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current year = 2025 , so age = 2025 - birthdate\n",
    "\n",
    "df1['age'] = 2025 - df1['birthdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba04ad-59be-453f-9ee7-9233cc83dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8b9de-510c-4539-9bca-fba80b7dc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping birthdate column since not so relevant again\n",
    "\n",
    "df1 = df1.drop('birthdate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360cd11-c0ba-45da-81f5-44443d898411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9cb5e-c308-4f8c-a2ff-1da03e2f7a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e088c06-ef12-4834-89d9-31f671035f4e",
   "metadata": {},
   "source": [
    "### Data understanding of second dataset(Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c467e2-0d32-44a4-9e88-d43be113e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176f988-3bb6-422b-b146-381081a7584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c48dd-9af2-4547-aa9d-4c60f2c847c5",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- There are 10 colums and 4368 rows with 4 numerical columns and 6 categorical columns\n",
    "- referredby column is the only feature with  missing value\n",
    "#### The target column is good_bad_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7f44c-383a-40d6-a9e4-c71db195f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of missing values in referredby column\n",
    "\n",
    "df2['referredby'].isna().sum() / 4368 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d36658c-cf24-4cd8-8f07-1a4138410c6a",
   "metadata": {},
   "source": [
    "Since it is very high , column will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c6279-1c98-425b-a957-4459fbd78a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant columns\n",
    "\n",
    "df2 = df2.drop(columns=['referredby'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9595c8b-a90c-45e4-8f42-f6858f10468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate values\n",
    "\n",
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48970154-4a69-436b-a473-b40b4db3c8aa",
   "metadata": {},
   "source": [
    "#### Creating loan_approval_min from approveddate and creationdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f423d31-2869-4a80-a83e-10593bf1fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['approveddate'] = df2['approveddate'].str.split('.').str[0]\n",
    "df2['creationdate'] = df2['creationdate'].str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6e3cb-306a-4855-a3be-58fefb00ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868c039-c51b-45d7-838e-9dbdd5cba5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['creationdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd0cbe9-cf6e-4d66-8879-7f530767fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['approveddate'] = pd.to_datetime(df2['approveddate'])\n",
    "df2['creationdate'] = pd.to_datetime(df2['creationdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c84471-a223-4f18-8be9-15cb25074d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['loan_approval_speed'] = df2['approveddate'] - df2['creationdate']\n",
    "df2['loan_approval_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106b2e3-3fda-4fed-895f-edad1f9b52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['loan_approval_min'] = (df2['loan_approval_speed'].dt.total_seconds() / 60).round(2)\n",
    "df2['loan_approval_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d3d8c-24f6-482c-a282-54047141e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5147f7f-01fa-4028-a923-3d7ee1dd80e5",
   "metadata": {},
   "source": [
    "### Data understanding of third dataset(Previous_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaebeef-7de2-4978-9b20-ecccadf1f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f66cd-c651-4daf-bd57-a74d80eab3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d03bf812-3ff2-4cc0-a03b-e332642d9beb",
   "metadata": {},
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ea7b1-35c8-444f-9319-9e396ecc7cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['customerid'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af98fa-560a-4c3a-824a-590974b2e8bd",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- So there are 12 columns and 18183 rows with only referredby column having missing values\n",
    "- It shares a common column customerid with the other 2 datsets\n",
    "- The customer id is meant to be a unique identifier but some rows share the same customerid\n",
    "-  presence of duplicates in customerid column ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea6c2a-ba87-44ab-ba17-4ed4a977c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the time(0:00:00) from the follwing columns to make them more meaningful\n",
    "\n",
    "for col in ['approveddate','creationdate','closeddate','firstduedate','firstrepaiddate']:\n",
    "    df3[col] = df3[col].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a2922-8e29-4f5a-b591-7fa4337bad4b",
   "metadata": {},
   "source": [
    "\n",
    "#### Creating a new column called payment_status ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8943d-9dd2-4fff-b810-762bd3dd015d",
   "metadata": {},
   "source": [
    "Using the firstduedate and firstrepaiddate we are going to form a column called payment status.\n",
    "- The firstduedate tells us the first expected date of payment of due\n",
    "- The  firstrepaiddate tells us the actual date that the customer paid the first payment.\n",
    "\n",
    "So comparing the firstrepaiddate and firstduedate can tell us if a customer made payment EARLY ,ONTIME or LATE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37031c-0b71-4625-bad5-2ef5ae38fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns to date format for easy comparison\n",
    "\n",
    "df3['firstrepaiddate']  = pd.to_datetime(df3['firstrepaiddate'] )\n",
    "df3['firstduedate'] =  pd.to_datetime(df3['firstduedate'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c420a71-0c9b-4023-ba06-bbbf4db18cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compare dates and return payment status\n",
    "\n",
    "def get_payment_status(row):\n",
    "    if row['firstrepaiddate'] == row['firstduedate']:\n",
    "        return 'ontime'\n",
    "    elif row['firstrepaiddate'] < row['firstduedate']:\n",
    "        return 'early'\n",
    "    else:\n",
    "        return 'late'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2290ed-890b-41bb-901c-b745f8ea38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the function to each row in the DataFrame and creating the overall_payment_status column\n",
    "\n",
    "df3['overall_payment_status'] = df3.apply(get_payment_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc1d9f-756a-4b08-be45-91c9d9e4a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping irrelevant columns which will not be needed\n",
    "\n",
    "df3 = df3.drop(columns=['systemloanid','approveddate','creationdate','loanamount','totaldue','termdays','referredby'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55218e3c-3627-4764-988c-845257e8536e",
   "metadata": {},
   "source": [
    "#### Creating payment_status_score \n",
    "The code below gives each overall payment status a score inorder to later create Repayment Behaviour Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d76e8-ef45-4afe-8c4c-7579d1cdac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giving each paymentstatus a score e.g early-5\n",
    "\n",
    "status_score = {\n",
    "    'early': 5,\n",
    "    'ontime': 4.5,\n",
    "    'late': -5\n",
    "}\n",
    "df3['payment_status_score'] = df3['overall_payment_status'].map(status_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32556b8b-d2dd-4e52-ae47-babd8eebe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f661815-fab6-40e1-b473-208f726f9a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5f153-c1d4-49c3-85a4-a7e7b2cb4137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['late_df'] = (df3['payment_status_score'] == -5.0).astype(int)\n",
    "df3['early_df'] = df3['payment_status_score'].isin([4.5,5.0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe54f52-0b01-484f-a0e6-23fa2bbfe433",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_payments_count = df3.groupby('customerid')['early_df'].sum().reset_index(name='early_payments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4de60-c59f-434a-9dc6-652ec52baac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "late_payments_count = df3.groupby('customerid')['late_df'].sum().reset_index(name='late_payments')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32b198-3e2a-47fa-8bbb-396209387f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_count = pd.merge(early_payments_count,late_payments_count, on='customerid',how='left')\n",
    "payments_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa82de4-e158-4f03-8de2-1befc2a92642",
   "metadata": {},
   "source": [
    "#### Creating repayment_score\n",
    "This is a sum total of the payment_score of rows with the SAME CUSTOMER ID  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bf030-6a8c-42a9-9bb0-f69701cfe1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_repayment_score = df3.groupby('customerid')['payment_status_score'].agg(lambda x: x.sum()).reset_index()\n",
    "df3_repayment_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97321903-f911-4a31-814c-63c967dd7d14",
   "metadata": {},
   "source": [
    "### Merging payment_count and repayment_score together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c28789-3d1c-4f30-8d69-67f111e8fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_best = pd.merge(payments_count,df3_repayment_score,on ='customerid')\n",
    "df3_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a469a0-5ffe-4996-8fcd-8c56c1c7b21a",
   "metadata": {},
   "source": [
    "### Merging dataset1 and dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b768d-7f0f-4545-b221-b8c897a96b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df1,df2, on ='customerid' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d859945-1b56-448e-944b-9f033157d2e8",
   "metadata": {},
   "source": [
    "#### MERGING DATASET4 AND ENGINEERED DF3_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a704cef-24f2-42a5-be23-dc32f6980a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df4,df3_best, on ='customerid')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf318b-19b1-43b0-b290-a43ccaa76894",
   "metadata": {},
   "source": [
    "\n",
    "#### Creating Custom Repayment-behaviour-score(RBS) from pastloans and payment-status-score\n",
    "To calculate our custom Repayment-behaviour-score(RBS) we divide payment_status_score by total number of previousloans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba0c6c-321b-4f78-9621-90e17c764988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get amount of previous loans taken we do loan amount(current amount of loans taken) subtracted by 1(subtract by 1 to exclude present loan taken)\n",
    "df['pastloans'] = df['loannumber'] - 1\n",
    "\n",
    "#Divide totalpayment_status_score by pastloans takento get RBS\n",
    "df['repayment_behaviour_score'] = df['payment_status_score'] / df['pastloans'] \n",
    "df['repayment_behaviour_score'] = df['repayment_behaviour_score'].round(2) * 100\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a964ddc-4838-4160-a216-0930bb2da987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the following columns\n",
    "df = df.drop(columns=['pastloans','bank_name_clients', 'loan_approval_speed'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c575e4c-eeec-4249-86f5-d1381e14dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089cf6b4-e334-48e3-83df-7febd587c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('loan_defaulters.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28e0e6-5441-4226-bae4-64be099b01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['customerid' ,'systemloanid', 'approveddate','creationdate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4076ac8-9fa0-411c-92e4-2b41cef4aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c08a38-f075-4151-8e83-48a4aebd40d8",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc250c8-7ff2-4232-856e-34c610abff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['good_bad_flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc2792-4e7b-4b1e-8b33-6ee2e2bc8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x =df['good_bad_flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03067a2c-8fc4-4426-b104-9e6547f1a4cf",
   "metadata": {},
   "source": [
    "### Observation\n",
    "There is presence of oversampling \n",
    ",the good class is more than the bad class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48b319-429b-4af5-85c5-ddcf2b2daa4c",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71102417-43a9-48fc-af7e-d9a8639ad664",
   "metadata": {},
   "source": [
    "#### Encoding of target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d515e4-fdcf-478e-83d4-b03108040657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder,StandardScaler\n",
    "lb_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ee8d2-1b74-4736-b124-6a66bd12e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['good_bad_flag'] = lb_encoder.fit_transform(df['good_bad_flag'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49296e-08aa-440d-aac7-824b75893dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['good_bad_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47daa403-0379-4bb2-9ffc-2288d7782692",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('good_bad_flag',axis=1)\n",
    "y = df['good_bad_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d4a33-8eed-4848-bbbe-1469c61ff0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = x.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = x.select_dtypes(include=np.number).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc88119-f7cd-435a-94a9-b9daa334122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b1990-7ed8-480a-ae39-5c4396cf3e43",
   "metadata": {},
   "source": [
    "#### Splitting our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854287f6-4024-4bdd-bc65-68d6a1055cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05, random_state=42 , stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dabf6a8-c045-49bb-8456-0330f780d8f9",
   "metadata": {},
   "source": [
    "### Creation of Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e109a7-9436-4fcc-a393-8d3a54b37ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d6f13-de74-4914-b521-9351722c2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "# Train pipeline\n",
    "pipeline.fit(x_train, y_train)\n",
    "# Save pipeline instead of raw model\n",
    "joblib.dump(pipeline, \"loan_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715274ed-98b8-4074-85fd-7c633cc70eac",
   "metadata": {},
   "source": [
    "#### Encoding and Scaling using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54efe0-08ce-4451-82d2-8862fd0b1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transform raw features\n",
    "x_train_transformed = preprocessor.fit_transform(x_train)\n",
    "x_test_transformed = preprocessor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8abbfd-a2de-4529-823e-1951fe2efb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9df1c-b1e1-463d-ac67-3482fabc86f9",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb20ed6-44a9-44fe-8e89-99fa0f7188a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993f74f-39b7-4e15-9a9b-4587f82f62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3535b8c8-279e-4be7-9fdb-363bdd0fbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74dba8-95c4-4b54-ab26-32dc28073153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70381054-4714-4438-b580-328c3cd5a7a6",
   "metadata": {},
   "source": [
    "#### Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f76db-5bd4-4a8e-bb3e-09a4fe3669ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score,confusion_matrix,recall_score,precision_score,classification_report,f1_score,ConfusionMatrixDisplay)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed7d8d36-ff88-4081-b6ee-ffa4cc38eeea",
   "metadata": {},
   "source": [
    "HYPERPARAMETER TUNING\n",
    "\n",
    "Decision tree , Logistic regression\n",
    "classweight=balanced\n",
    "\n",
    "randomforest\n",
    "classweight=balanced\n",
    "\n",
    "lightgbm\n",
    "is_unbalance =true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed9ca9-f965-4c4a-b73a-5b219fd8827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42,class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42,class_weight='balanced'),\n",
    "    'XG Boost': XGBClassifier(random_state=42),\n",
    "    'Light GBM': LGBMClassifier(random_state=42,is_unbalance=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc164059-8bfc-492c-9bb8-e69bf21300d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= {}\n",
    "fig,axes = plt.subplots(1,5,figsize=(18,4))\n",
    "\n",
    "for (name,model), ax in zip(models.items(),axes.flatten()):\n",
    "    #training the model\n",
    "    model.fit(x_train_transformed,y_train)\n",
    "\n",
    "    #making predictions\n",
    "    train_pred = model.predict(x_train_transformed)\n",
    "    test_pred =model.predict(x_test_transformed)\n",
    "\n",
    "    #evaluating model prediction\n",
    "    #Accuracy:\n",
    "    train_score = accuracy_score(y_train, train_pred)\n",
    "    test_score = accuracy_score(y_test,test_pred)\n",
    "    #Precision for class 0:\n",
    "    precision = precision_score(y_test,test_pred, pos_label=0)\n",
    "    #Recall for class 0:\n",
    "    recall = recall_score(y_test,test_pred,pos_label=0)\n",
    "    #F1 score for class 0\n",
    "    f1 = f1_score(y_test,test_pred,pos_label=0)\n",
    "\n",
    "    #storing evaluation to results dictionary\n",
    "    results[name] = {\n",
    "        'Train_Accuracy' : train_score,\n",
    "        'Test_Accuracy' : train_score,\n",
    "        'Precision_0' : precision,\n",
    "        'Recall_0' : recall,\n",
    "        'F1 Score_0': f1\n",
    "        \n",
    "    }\n",
    "    #Confusion_matrix\n",
    "    cm = confusion_matrix(test_pred,y_test)\n",
    "    # cm2 = confusion_matrix(train_pred,y_train)\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(cm)\n",
    "    # disp = ConfusionMatrixDisplay(cm2)\n",
    "    disp.plot(ax=ax, cmap='Blues')\n",
    "    ax.set_title(name)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "print(metrics_df.round(3))\n",
    "\n",
    "\n",
    "\n",
    "#those staying - 0\n",
    "#those going -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c1a7b-6a35-475a-bba5-78fc05b1aaca",
   "metadata": {},
   "source": [
    "### Model improvement : Balancing oversampling in good_bad_flag feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a398c7a-41c6-411d-b2a0-303a78e62463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.over_sampling import ADASYN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3fc09e-a3a6-4a8e-98a3-29b007af7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled,y_train_resampled = smote.fit_resample(x_train_transformed,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242f2c9-0265-4304-a88c-40afc4240875",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef64e27-47ed-45fd-95d8-ec95fe7e0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= {}\n",
    "fig,axes = plt.subplots(1,5,figsize=(18,4))\n",
    "\n",
    "for (name,model), ax in zip(models.items(),axes.flatten()):\n",
    "    #training the model\n",
    "    model.fit(x_train_resampled,y_train_resampled)\n",
    "\n",
    "    #making predictions\n",
    "    train_pred = model.predict(x_train_resampled)\n",
    "    test_pred = model.predict(x_test_transformed)\n",
    "\n",
    "    #evaluating model prediction\n",
    "    #Accuracy:\n",
    "    train_score = accuracy_score(y_train_resampled, train_pred)\n",
    "    test_score = accuracy_score(y_test,test_pred)\n",
    "    #Precision for 0:\n",
    "    precision = precision_score(y_test,test_pred, pos_label=0)\n",
    "    #Recall for 0:\n",
    "    recall = recall_score(y_test,test_pred, pos_label=0)\n",
    "    # F1 score for 0\n",
    "    f1 = f1_score(y_test,test_pred, pos_label=0)\n",
    "    \n",
    "\n",
    "    #storing evaluation to results dictionary\n",
    "    results[name] = {\n",
    "        'Train_Accuracy' : train_score,\n",
    "        'Test_Accuracy' : train_score,\n",
    "        'Precision_0' : precision,\n",
    "        'Recall_0' : recall,\n",
    "        'F1 Score_0': f1\n",
    "    }\n",
    "    #Confusion_matrix\n",
    "    cm = confusion_matrix(test_pred,y_test)\n",
    "    disp = ConfusionMatrixDisplay(cm)\n",
    "    disp.plot(ax=ax, cmap='Blues')\n",
    "    ax.set_title(name)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "print(metrics_df.round(3))\n",
    "\n",
    "\n",
    "\n",
    "#those staying - 0\n",
    "#those going -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91978bf-ef04-4292-97d1-d6939a433ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afda46a-1b02-4456-9e4e-d67029ecbc05",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d796ca-da72-4c7c-916c-14df49b02563",
   "metadata": {},
   "source": [
    "##### Model performance dropped after applying SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43beeaef-4fdf-4eb2-9ba4-2a6bfda4588b",
   "metadata": {},
   "source": [
    "### Logistic regression stands out:\n",
    "Logistic Regression is the best-performing model for this task due to it's high recall for defaulters of 0.694. Despite having higher False Positives, it significantly outperforms others in identifying actual defaulters, which aligns with the business objective of minimizing financial risk.\n",
    "- As a result Logistic regression will be deployed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e3d67-e837-480a-a099-0d775abcadc0",
   "metadata": {},
   "source": [
    "## Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c95b1-9473-4408-ae43-fa0939527f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install streamlit\n",
    "#Deployment was carried out in app.py file in folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e06785-b4fd-467e-a7d2-901ec0238f05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
